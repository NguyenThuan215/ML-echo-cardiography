{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "echocardiography.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "fuTypVjk3u44"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NguyenThuan215/ML-echo-cardiography/blob/main/echocardiography.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5rBZThh_9ks"
      },
      "source": [
        "# Thư viện"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwSbWxosZDuO"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "from collections import namedtuple\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3-hbUu0AJhf"
      },
      "source": [
        "# Kết nối với data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNtq4N34h4OD"
      },
      "source": [
        "# drive.mount(\"/content/drive\")\n",
        "# !unzip -uq \"/content/drive/My Drive/DATA_CHAMBER_2021.zip\" -d \"./\"\n",
        "# traindir = \"DATA_CHAMBER_2021/train\"\n",
        "# testdir = \"DATA_CHAMBER_2021/test\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlyWEgSxM2Xj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b670cd38-145b-4d6c-f4fa-27a47c6d8db3"
      },
      "source": [
        "!git clone https://github.com/NguyenThuan215/ML-echo-cardiography\n",
        "traindir = \"/content/ML-echo-cardiography/DATA_CHAMBER_2021/train\"\n",
        "testdir = \"/content/ML-echo-cardiography/DATA_CHAMBER_2021/test\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ML-echo-cardiography'...\n",
            "remote: Enumerating objects: 8348, done.\u001b[K\n",
            "remote: Counting objects: 100% (8348/8348), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8345/8345), done.\u001b[K\n",
            "remote: Total 8348 (delta 10), reused 8327 (delta 1), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (8348/8348), 488.03 MiB | 27.04 MiB/s, done.\n",
            "Resolving deltas: 100% (10/10), done.\n",
            "Checking out files: 100% (8328/8328), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3T3aJgXAhM2"
      },
      "source": [
        "# Chuẩn bị dữ liệu:\n",
        "1. Các lớp: {2C, 3C, 4C}\n",
        "2. Đọc dữ liệu trong file 'traindir' và 'testdir'\n",
        "3. Đưa dữ liệu vào các batch để xử lý song song\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLgVpzcHrnw7"
      },
      "source": [
        "TrainTest = namedtuple('TrainTest', ['train', 'test'])\n",
        "\n",
        "def get_classes():\n",
        "  classes = ['2C', '3C', '4C']\n",
        "  return classes\n",
        "\n",
        "def prepare_data():\n",
        "  image_size = 224\n",
        "  transform_train = transforms.Compose([\n",
        "      transforms.Resize((image_size,image_size)),                                    \n",
        "      transforms.ToTensor(),\n",
        "  ])\n",
        "  transform_test = transforms.Compose([\n",
        "      transforms.Resize((image_size,image_size)),\n",
        "      transforms.ToTensor(),\n",
        "  ])\n",
        "  trainset = torchvision.datasets.ImageFolder(root=traindir, transform=transform_train)\n",
        "  testset = torchvision.datasets.ImageFolder(root=testdir, transform=transform_test)\n",
        "  return TrainTest(train=trainset, test=testset)\n",
        "\n",
        "def prepare_loader(datasets):\n",
        "  batch = 32\n",
        "  worker = 4\n",
        "  trainloader = DataLoader(dataset=datasets.train, batch_size=batch, shuffle=True, num_workers=worker)\n",
        "  testloader = DataLoader(dataset=datasets.test, batch_size=batch, shuffle=False, num_workers=worker)\n",
        "  return TrainTest(train=trainloader, test=testloader)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWt-FpAWCE-b"
      },
      "source": [
        "# Train/Test mô hình:\n",
        "1. Train: với mỗi batch trong tập train:\n",
        "  - Cho ảnh đi qua model\n",
        "  - Tính lỗi bằng hàm lỗi \"loss_func\"\n",
        "  - Cập nhật tham số\n",
        "  - Báo cáo sau \"reporting_steps\" bước\n",
        "2. Test:\n",
        "  - Đặt model ở chế độ đánh giá (evaluate)\n",
        "  - Tính toán đầu ra cho từng ảnh\n",
        "  - trả về nhãn dự đoán/nhãn thực"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfc1-9U4OVSo"
      },
      "source": [
        "def train_epoch(epoch, model, loader, loss_func, optimizer, device):\n",
        "  model.train()\n",
        "  running_loss = 0.0\n",
        "  reporting_steps = 40\n",
        "  step = 0\n",
        "  for images, labels in loader:\n",
        "    step += 1\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    outputs = model(images)\n",
        "    loss = loss_func(outputs, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    if step % reporting_steps == reporting_steps - 1:\n",
        "      print(f\"Epoch {epoch} step {step} ave_loss {running_loss/reporting_steps:.4f}\")\n",
        "      running_loss = 0.0\n",
        "\n",
        "def test_epoch(epoch, model, loader, device):\n",
        "  ytrue = []\n",
        "  ypred = []\n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    for images, labels in loader:\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "      outputs = model(images)\n",
        "      _, predicted = torch.max(outputs, dim=1)\n",
        "      ytrue += list(labels.cpu().numpy())\n",
        "      ypred += list(predicted.cpu().numpy())\n",
        "\n",
        "  return ypred, ytrue"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5-WLwvCFQp1"
      },
      "source": [
        "# Tạo và thực nghiệm mô hình:\n",
        "1. Tham số truyền vào main:\n",
        "  - \"PATH\": file lưu lại mô hình\n",
        "  - \"model_in\": string thể hiện tên mô hình muốn thực nghiệm.\n",
        "2. Sửa đổi đầu ra của lớp Linear cuối cùng thành \"3\" để phù hợp với yêu cầu bào toán\n",
        "3. Sử dụng hàm lỗi CrossEntropyLoss, hàm tối ưu SGD (Stochastic Gradient Descent)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWfJ2IN6iObn"
      },
      "source": [
        "def main(PATH='./model.pth', model_in=None):\n",
        "  classes = get_classes()\n",
        "  datasets = prepare_data()\n",
        "  loaders = prepare_loader(datasets)\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "  print(\"Num Images in train set:\", len(datasets.train))\n",
        "  print(\"Num Images in test set:\", len(datasets.test))\n",
        "  print(\"Num batch in train set: \", len(loaders.train))\n",
        "  print(\"class: \", datasets.train.class_to_idx)\n",
        "  print(\"image size: \", datasets.train[0][0].shape)\n",
        "  print(\"device:\", device)\n",
        "  print(\"model:\", model_in)\n",
        "\n",
        "  if model_in == 'vgg16':  \n",
        "    model = torchvision.models.vgg16()\n",
        "    model.classifier[6] = torch.nn.modules.linear.Linear(in_features=4096, out_features=3, bias=True)\n",
        "  elif model_in == 'resnet50':\n",
        "    model = torchvision.models.resnet50()\n",
        "    model.fc = torch.nn.modules.linear.Linear(in_features=2048, out_features=3, bias=True) \n",
        "  elif model_in == 'resnet18':\n",
        "    model = torchvision.models.resnet18()\n",
        "    model.fc = torch.nn.modules.linear.Linear(in_features=512, out_features=3, bias=True) \n",
        "  else: \n",
        "    # model = torchvision.models.googlenet()\n",
        "    # model.fc.out_features = 3\n",
        "    pass\n",
        "\n",
        "\n",
        "  model.to(device=device)\n",
        "  loss_func = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "  accuracies = []\n",
        "  for epoch in range(10):\n",
        "    print(\"---------------------------------------------------------------\")\n",
        "    print(f\"\\nEpoch {epoch} report: \")\n",
        "    train_epoch(epoch, model, loaders.train, loss_func, optimizer, device)\n",
        "    ypred_test, ytrue_test = test_epoch(epoch, model, loaders.test, device)\n",
        "    print(\"Test report: \\n\", classification_report(ytrue_test, ypred_test, target_names=classes))\n",
        "    torch.save(model.state_dict(), PATH)\n",
        "\n",
        "    # calculate accurency\n",
        "    ypred_test = np.array(ypred_test)\n",
        "    ytrue_test = np.array(ytrue_test)\n",
        "    accuracy = (ytrue_test==ypred_test).sum() / len(ytrue_test)\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "\n",
        "  fig, ax1 = plt.subplots(1,1, figsize=(8,4))\n",
        "  ax1.plot(accuracies, \"bo--\", label=model_in)\n",
        "  ax1.set(title=model_in, xlabel=\"epoch\", ylabel=\"accuracy\"+ model_in, xlim=(-0.5,10), ylim=(0,1))\n",
        "  plt.show()\n",
        "\n",
        "  return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNaRMKd7bEW5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edad3195-0829-4b36-97a9-289ec1d36785"
      },
      "source": [
        "model = main(PATH=\"./vgg16.pth\", model_in='vgg16')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num Images in train set: 6717\n",
            "Num Images in test set: 1607\n",
            "Num batch in train set:  210\n",
            "<class 'torch.utils.data.dataloader.DataLoader'>\n",
            "class:  {'2C': 0, '3C': 1, '4C': 2}\n",
            "image size:  torch.Size([3, 224, 224])\n",
            "device: cuda\n",
            "model: vgg16\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Epoch 0 report: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 step 39 ave_loss 1.0651\n",
            "Epoch 0 step 79 ave_loss 0.8773\n",
            "Epoch 0 step 119 ave_loss 0.5270\n",
            "Epoch 0 step 159 ave_loss 0.3648\n",
            "Epoch 0 step 199 ave_loss 0.9026\n",
            "Test report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.54      0.72      0.62       409\n",
            "          3C       0.57      0.81      0.67       367\n",
            "          4C       1.00      0.65      0.79       831\n",
            "\n",
            "    accuracy                           0.71      1607\n",
            "   macro avg       0.70      0.73      0.69      1607\n",
            "weighted avg       0.78      0.71      0.72      1607\n",
            "\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Epoch 1 report: \n",
            "Epoch 1 step 39 ave_loss 0.3395\n",
            "Epoch 1 step 79 ave_loss 0.2141\n",
            "Epoch 1 step 119 ave_loss 0.1455\n",
            "Epoch 1 step 159 ave_loss 0.0924\n",
            "Epoch 1 step 199 ave_loss 0.0457\n",
            "Test report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.78      0.77      0.77       409\n",
            "          3C       0.58      1.00      0.73       367\n",
            "          4C       1.00      0.68      0.81       831\n",
            "\n",
            "    accuracy                           0.78      1607\n",
            "   macro avg       0.79      0.82      0.77      1607\n",
            "weighted avg       0.85      0.78      0.78      1607\n",
            "\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Epoch 2 report: \n",
            "Epoch 2 step 39 ave_loss 0.0485\n",
            "Epoch 2 step 79 ave_loss 0.0523\n",
            "Epoch 2 step 119 ave_loss 0.0483\n",
            "Epoch 2 step 159 ave_loss 0.0113\n",
            "Epoch 2 step 199 ave_loss 0.0358\n",
            "Test report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.94      0.78      0.85       409\n",
            "          3C       0.86      0.96      0.90       367\n",
            "          4C       0.92      0.95      0.94       831\n",
            "\n",
            "    accuracy                           0.91      1607\n",
            "   macro avg       0.91      0.90      0.90      1607\n",
            "weighted avg       0.91      0.91      0.91      1607\n",
            "\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Epoch 3 report: \n",
            "Epoch 3 step 39 ave_loss 0.0857\n",
            "Epoch 3 step 79 ave_loss 0.0373\n",
            "Epoch 3 step 119 ave_loss 0.0084\n",
            "Epoch 3 step 159 ave_loss 0.0425\n",
            "Epoch 3 step 199 ave_loss 0.0209\n",
            "Test report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.93      0.89      0.91       409\n",
            "          3C       0.70      0.93      0.80       367\n",
            "          4C       0.98      0.86      0.92       831\n",
            "\n",
            "    accuracy                           0.88      1607\n",
            "   macro avg       0.87      0.89      0.88      1607\n",
            "weighted avg       0.90      0.88      0.89      1607\n",
            "\n",
            "---------------------------------------------------------------\n",
            "\n",
            "Epoch 4 report: \n",
            "Epoch 4 step 39 ave_loss 0.0103\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvIUwXOnbRfy"
      },
      "source": [
        "model = main(PATH=\"./resnet18.pth\", model_in='resnet18')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11IjyYmDbRvH"
      },
      "source": [
        "model = main(PATH=\"./resnet50.pth\", model_in='resnet50')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzp1_ZjFxJMB"
      },
      "source": [
        "# model = main(PATH=\"./googlenet.pth\", model_in='googlenet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuTypVjk3u44"
      },
      "source": [
        "# Vẽ Biểu đồ"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQCAJH9LXDsu"
      },
      "source": [
        "# vgg16_64 = [0.25, 0.43, 0.66, 0.72, 0.80, 0.87, 0.90, 0.90, 0.90, 0.91]\n",
        "# vgg16_224 = [0.25, 0.61, 0.78, 0.83, 0.86, 0.87, 0.88, 0.92, 0.89, 0.90]\n",
        "\n",
        "# resnet18_64 = [0.56, 0.63, 0.75, 0.85, 0.89, 0.90, 0.90, 0.91, 0.90, 0.91]\n",
        "# resnet18_224 = [0.65, 0.53, 0.71, 0.81, 0.83, 0.89, 0.90, 0.91, 0.90, 0.92]\n",
        "\n",
        "# resnet50_64 = [0.65, 0.80, 0.79, 0.78, 0.80, 0.77, 0.83, 0.82, 0.82, 0.84]\n",
        "# resnet50_224 = [0.61, 0.77, 0.83, 0.83, 0.86, 0.81, 0.83, 0.89, 0.85, 0.87]\n",
        "\n",
        "# net = [vgg16_64, vgg16_224, resnet18_64, resnet18_224, resnet50_64, resnet50_224]\n",
        "# fig, ((ax1, ax2), (ax3, ax4), (ax5, ax6)) = plt.subplots(3,2, figsize=(15,18))\n",
        "\n",
        "# ax1.plot(vgg16_64, \"bo--\", label=\"64x64\")\n",
        "# ax1.set(title=\"VGG16 64x64\", xlabel=\"epoch\", ylabel=\"accuracy\",xlim=(-0.5,10), ylim=(0,1))\n",
        "# ax2.plot(vgg16_224, \"go--\", label=\"224x224\")\n",
        "# ax2.set(title=\"VGG16 224x224\", xlabel=\"epoch\", ylabel=\"accuracy\", xlim=(-0.5,10), ylim=(0,1))\n",
        "\n",
        "# ax3.plot(resnet18_64, \"bo--\", label=\"64x64\")\n",
        "# ax3.set(title=\"RESNET18 64x64\", xlabel=\"epoch\", ylabel=\"accuracy\",xlim=(-0.5,10), ylim=(0,1))\n",
        "# ax4.plot(resnet18_224, \"go--\", label=\"224x224\")\n",
        "# ax4.set(title=\"RESNET18 224x224\", xlabel=\"epoch\", ylabel=\"accuracy\", xlim=(-0.5,10), ylim=(0,1))\n",
        "\n",
        "# ax5.plot(resnet50_64, \"bo--\", label=\"64x64\")\n",
        "# ax5.set(title=\"RESNET50 64x64\", xlabel=\"epoch\", ylabel=\"accuracy\",xlim=(-0.5,10), ylim=(0,1))\n",
        "# ax6.plot(resnet50_224, \"go--\", label=\"224x224\")\n",
        "# ax6.set(title=\"RESNET50 224x224\", xlabel=\"epoch\", ylabel=\"accuracy\", xlim=(-0.5,10), ylim=(0,1))\n",
        "\n",
        "# fig.xlabel=\"x\"\n",
        "# fig.ylabel=\"y\"\n",
        "# plt.show()\n",
        "\n",
        "# c = []\n",
        "\n",
        "# a = [1,2,1,1,2, 1,1 ,1,2,2]\n",
        "# b = [1,2,2,1,2, 2,1 ,1,2,2]\n",
        "# a = np.array(a)\n",
        "# b = np.array(b)\n",
        "\n",
        "\n",
        "# c.append((a==b).sum() / len(a))\n",
        "# c.append((a!=b).sum() / len(a))\n",
        "\n",
        "# fig, ax1 = plt.subplots(1,1, figsize=(8,4))\n",
        "\n",
        "# ax1.plot(a, \"bo--\", label=\"64x64\")\n",
        "# ax1.set(title=\"VGG16 64x64\", xlabel=\"epoch\", ylabel=\"accuracy\",xlim=(-0.5,10), ylim=(0,3))\n",
        "# ax2.plot(vgg16_224, \"go--\", label=\"224x224\")\n",
        "# ax2.set(title=\"VGG16 224x224\", xlabel=\"epoch\", ylabel=\"accuracy\", xlim=(-0.5,10), ylim=(0,1))\n",
        "\n",
        "# ax3.plot(resnet18_64, \"bo--\", label=\"64x64\")\n",
        "# ax3.set(title=\"RESNET18 64x64\", xlabel=\"epoch\", ylabel=\"accuracy\",xlim=(-0.5,10), ylim=(0,1))\n",
        "# ax4.plot(resnet18_224, \"go--\", label=\"224x224\")\n",
        "# ax4.set(title=\"RESNET18 224x224\", xlabel=\"epoch\", ylabel=\"accuracy\", xlim=(-0.5,10), ylim=(0,1))\n",
        "\n",
        "# ax5.plot(resnet50_64, \"bo--\", label=\"64x64\")\n",
        "# ax5.set(title=\"RESNET50 64x64\", xlabel=\"epoch\", ylabel=\"accuracy\",xlim=(-0.5,10), ylim=(0,1))\n",
        "# ax6.plot(resnet50_224, \"go--\", label=\"224x224\")\n",
        "# ax6.set(title=\"RESNET50 224x224\", xlabel=\"epoch\", ylabel=\"accuracy\", xlim=(-0.5,10), ylim=(0,1))\n",
        "\n",
        "# fig.xlabel=\"x\"\n",
        "# fig.ylabel=\"y\"\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}