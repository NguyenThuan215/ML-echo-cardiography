{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "echocardiography.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NguyenThuan215/ML-echo-cardiography/blob/main/echocardiography.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5rBZThh_9ks"
      },
      "source": [
        "# Thư viện"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwSbWxosZDuO"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "from collections import namedtuple\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3-hbUu0AJhf"
      },
      "source": [
        "# Kết nối với data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlyWEgSxM2Xj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e8c658e-0836-4330-9b91-89eb6882b9d7"
      },
      "source": [
        "!git clone https://github.com/NguyenThuan215/ML-echo-cardiography\n",
        "traindir = \"/content/ML-echo-cardiography/DATA_CHAMBER_2021/train\"\n",
        "testdir = \"/content/ML-echo-cardiography/DATA_CHAMBER_2021/test\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ML-echo-cardiography'...\n",
            "remote: Enumerating objects: 8357, done.\u001b[K\n",
            "remote: Total 8357 (delta 0), reused 0 (delta 0), pack-reused 8357\u001b[K\n",
            "Receiving objects: 100% (8357/8357), 488.05 MiB | 30.69 MiB/s, done.\n",
            "Resolving deltas: 100% (19/19), done.\n",
            "Checking out files: 100% (8328/8328), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3T3aJgXAhM2"
      },
      "source": [
        "# Chuẩn bị dữ liệu:\n",
        "1. Các lớp: {2C, 3C, 4C}\n",
        "2. Đọc dữ liệu trong file 'traindir' và 'testdir'\n",
        "3. Đưa dữ liệu vào các batch để xử lý song song\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLgVpzcHrnw7"
      },
      "source": [
        "TrainTest = namedtuple('TrainTest', ['train', 'test'])\n",
        "\n",
        "def get_classes():\n",
        "  classes = ['2C', '3C', '4C']\n",
        "  return classes\n",
        "\n",
        "#Generate different transformations \n",
        "to_tensor = transforms.ToTensor()\n",
        "normalize = transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "hor_flip = transforms.RandomHorizontalFlip(p=0.3)\n",
        "ver_flip = transforms.RandomVerticalFlip(p=0.3)\n",
        "rotation_15 = transforms.RandomRotation(degrees=15)\n",
        "rotation_10 = transforms.RandomRotation(degrees=10)\n",
        "crop = transforms.RandomCrop(224, padding=4)\n",
        "equalize = transforms.RandomEqualize(p=1)\n",
        "blur = transforms.GaussianBlur(kernel_size=3)\n",
        "resize_224 = transforms.Resize((224,224))\n",
        "resize_64 = transforms.Resize((64,64))\n",
        "resize_32 = transforms.Resize((32,32))\n",
        "\n",
        "#transform for train set\n",
        "transform_train_normal = transforms.Compose([resize_224, to_tensor])\n",
        "transform_train_64 = transforms.Compose([resize_64, to_tensor])\n",
        "transform_train_32 = transforms.Compose([resize_32, to_tensor])\n",
        "transform_train_aug = transforms.Compose([resize_224, hor_flip, ver_flip, rotation_10, to_tensor])\n",
        "transform_train_preprocess =  transforms.Compose([resize_224, equalize, blur, to_tensor])\n",
        "\n",
        "#transform for test set\n",
        "transform_test_normal = transforms.Compose([resize_224, to_tensor])\n",
        "transform_test_64 = transforms.Compose([resize_64, to_tensor])\n",
        "transform_test_32 = transforms.Compose([resize_32, to_tensor])\n",
        "transform_test_preprocess =  transforms.Compose([resize_224, equalize, blur, to_tensor])\n",
        "\n",
        "def creat_transforms(img_size=224, augmentation=\"None\"):\n",
        "  # img_size = 224,64,32\n",
        "  # augmentation = \"None\", \"preprocess\", \"augmentation\"\n",
        "  if augmentation == \"None\":\n",
        "    if (img_size == 224): \n",
        "      transforms_train = transform_train_normal\n",
        "      transforms_test = transform_test_normal\n",
        "    elif (img_size == 64): \n",
        "      transforms_train = transform_train_64\n",
        "      transforms_test = transform_test_64\n",
        "    elif (img_size == 32): \n",
        "      transforms_train = transform_train_32\n",
        "      transforms_test = transform_test_32\n",
        "    else:\n",
        "      pass\n",
        "  elif augmentation == \"preprocess\":\n",
        "    transforms_train = transform_train_preprocess\n",
        "    transforms_test = transform_test_preprocess\n",
        "  elif augmentation == \"augmentation\":\n",
        "    transforms_train = transform_train_aug\n",
        "    transforms_test = transform_test_normal\n",
        "  else:\n",
        "    pass\n",
        "  print(transforms_train, transforms_test)\n",
        "  return transforms_train, transforms_test\n",
        "\n",
        "  \n",
        "def prepare_data(transform_train=transform_train_normal, transform_test=transform_test_normal):\n",
        "  trainset = torchvision.datasets.ImageFolder(root=traindir, transform=transform_train)\n",
        "  testset = torchvision.datasets.ImageFolder(root=testdir, transform=transform_test)\n",
        "  return TrainTest(train=trainset, test=testset)\n",
        "\n",
        "def prepare_loader(datasets):\n",
        "  batch = 32\n",
        "  worker = 4\n",
        "  trainloader = DataLoader(dataset=datasets.train, batch_size=batch, shuffle=True, num_workers=worker)\n",
        "  testloader = DataLoader(dataset=datasets.test, batch_size=batch, shuffle=False, num_workers=worker)\n",
        "  return TrainTest(train=trainloader, test=testloader)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWt-FpAWCE-b"
      },
      "source": [
        "# Train/Test mô hình:\n",
        "1. Train: với mỗi batch trong tập train:\n",
        "  - Cho ảnh đi qua model\n",
        "  - Tính lỗi bằng hàm lỗi \"loss_func\"\n",
        "  - Cập nhật tham số\n",
        "  - Báo cáo sau \"reporting_steps\" bước\n",
        "2. Test:\n",
        "  - Đặt model ở chế độ đánh giá (evaluate)\n",
        "  - Tính toán đầu ra cho từng ảnh\n",
        "  - trả về nhãn dự đoán/nhãn thực"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfc1-9U4OVSo"
      },
      "source": [
        "def train_epoch(epoch, model, loader, loss_func, optimizer, device):\n",
        "  model.train()\n",
        "  running_loss = 0.0\n",
        "  final_loss = 0.0\n",
        "  reporting_steps = 40\n",
        "  step = 0\n",
        "  for images, labels in loader:\n",
        "    step += 1\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    outputs = model(images)\n",
        "    loss = loss_func(outputs, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    final_loss = loss.item()\n",
        "    running_loss += final_loss\n",
        "    if step % reporting_steps == reporting_steps - 1:\n",
        "      print(f\"Epoch {epoch} step {step} ave_loss {running_loss/reporting_steps:.4f}\")\n",
        "      running_loss = 0.0\n",
        "  return final_loss\n",
        "\n",
        "def test_epoch(epoch, model, loader, device):\n",
        "  ytrue = []\n",
        "  ypred = []\n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    for images, labels in loader:\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "      outputs = model(images)\n",
        "      _, predicted = torch.max(outputs, dim=1)\n",
        "      ytrue += list(labels.cpu().numpy())\n",
        "      ypred += list(predicted.cpu().numpy())\n",
        "\n",
        "  return ypred, ytrue"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5-WLwvCFQp1"
      },
      "source": [
        "# Tạo và thực nghiệm mô hình:\n",
        "1. Tham số truyền vào main:\n",
        "  - \"model_in\": string thể hiện tên mô hình muốn thực nghiệm.\n",
        "2. Sửa đổi đầu ra của lớp Linear cuối cùng thành \"3\" để phù hợp với yêu cầu bài toán\n",
        "3. Sử dụng hàm lỗi CrossEntropyLoss, hàm tối ưu SGD (Stochastic Gradient Descent)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJG47nRRMzwU"
      },
      "source": [
        "def creat_model(model_in=None, class_out=1000, device=\"cpu\"):\n",
        "  if model_in == 'vgg16':  \n",
        "    model = torchvision.models.vgg16(pretrained=False)\n",
        "    model.classifier[6] = torch.nn.modules.linear.Linear(in_features=4096, out_features=class_out, bias=True)\n",
        "  elif model_in == 'resnet50':\n",
        "    model = torchvision.models.resnet50(pretrained=False)\n",
        "    model.fc = torch.nn.modules.linear.Linear(in_features=2048, out_features=class_out, bias=True) \n",
        "  elif model_in == 'resnet18':\n",
        "    model = torchvision.models.resnet18(pretrained=False)\n",
        "    model.fc = torch.nn.modules.linear.Linear(in_features=512, out_features=class_out, bias=True) \n",
        "  elif model_in == 'densenet121': \n",
        "    model = torchvision.models.densenet121(pretrained=False)\n",
        "    model.classifier = torch.nn.modules.linear.Linear(in_features=1024, out_features=class_out, bias=True)\n",
        "  else:\n",
        "    pass\n",
        "    \n",
        "  model.to(device=device)\n",
        "  return model"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWfJ2IN6iObn"
      },
      "source": [
        "def main(model_in, img_size, augmentation):\n",
        "  PATH = \"./\" + model_in + '.pth'\n",
        "  classes = get_classes()\n",
        "  class_out = len(classes)\n",
        "\n",
        "  transforms_train, transforms_test = creat_transforms(img_size,augmentation)\n",
        "  datasets = prepare_data(transforms_train, transforms_test)\n",
        "  loaders = prepare_loader(datasets)\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "  print(\"image size: \", datasets.train[0][0].shape)\n",
        "  print(\"device:\", device)\n",
        "  print(\"model:\", model_in)\n",
        "\n",
        "  model = creat_model(model_in=model_in, class_out=class_out, device=device) \n",
        "  loss_func = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "  accuracies = []\n",
        "  losses = []\n",
        "  for epoch in range(20):\n",
        "    print(\"---------------------------------------------------------------\")\n",
        "    loss = train_epoch(epoch, model, loaders.train, loss_func, optimizer, device)\n",
        "    ypred_test, ytrue_test = test_epoch(epoch, model, loaders.test, device)\n",
        "\n",
        "    print(classification_report(ytrue_test, ypred_test, target_names=classes))\n",
        "    torch.save(model.state_dict(), PATH)\n",
        "\n",
        "    # calculate report\n",
        "    ypred_test = np.array(ypred_test)\n",
        "    ytrue_test = np.array(ytrue_test)\n",
        "    accuracy = int((ytrue_test==ypred_test).sum() / len(ytrue_test) *100)\n",
        "    accuracies.append(accuracy)\n",
        "    losses.append(round(loss, 4))\n",
        "\n",
        "    \n",
        "  print(\"model:\", model_in, \", size:\", img_size, \", augmentation:\", augmentation)\n",
        "  print(\"accr: \", accuracies)\n",
        "  print(\"loss: \", losses)\n",
        "  return model"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzp1_ZjFxJMB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c86740be-85d7-4d47-9ac6-bef22cc41ead"
      },
      "source": [
        "models = ['vgg16', 'resnet18', 'resnet50', 'densenet121']\n",
        "img_sizes = [224, 64, 32]\n",
        "augmentation = ['None', \"preprocess\", \"augmentation\"]\n",
        "\n",
        "for i in models:\n",
        "  model = main(model_in=i, img_size=224,augmentation=\"None\")"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Compose(\n",
            "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=None)\n",
            "    ToTensor()\n",
            ") Compose(\n",
            "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=None)\n",
            "    ToTensor()\n",
            ")\n",
            "image size:  torch.Size([3, 224, 224])\n",
            "device: cuda\n",
            "model: vgg16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------\n",
            "Epoch 0 step 39 ave_loss 1.0451\n",
            "Epoch 0 step 79 ave_loss 1.0439\n",
            "Epoch 0 step 119 ave_loss 1.0343\n",
            "Epoch 0 step 159 ave_loss 0.6680\n",
            "Epoch 0 step 199 ave_loss 0.4956\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.63      0.41      0.50       409\n",
            "          3C       0.44      0.97      0.60       367\n",
            "          4C       1.00      0.63      0.77       831\n",
            "\n",
            "    accuracy                           0.65      1607\n",
            "   macro avg       0.69      0.67      0.63      1607\n",
            "weighted avg       0.78      0.65      0.67      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 step 39 ave_loss 0.2354\n",
            "Epoch 1 step 79 ave_loss 0.2529\n",
            "Epoch 1 step 119 ave_loss 0.3077\n",
            "Epoch 1 step 159 ave_loss 0.1101\n",
            "Epoch 1 step 199 ave_loss 0.0682\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.94      0.78      0.85       409\n",
            "          3C       0.62      0.99      0.76       367\n",
            "          4C       1.00      0.81      0.90       831\n",
            "\n",
            "    accuracy                           0.85      1607\n",
            "   macro avg       0.85      0.86      0.84      1607\n",
            "weighted avg       0.90      0.85      0.85      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 step 39 ave_loss 0.0361\n",
            "Epoch 2 step 79 ave_loss 0.0335\n",
            "Epoch 2 step 119 ave_loss 0.0418\n",
            "Epoch 2 step 159 ave_loss 0.0114\n",
            "Epoch 2 step 199 ave_loss 0.0492\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.98      0.80      0.88       409\n",
            "          3C       0.67      1.00      0.80       367\n",
            "          4C       0.97      0.85      0.90       831\n",
            "\n",
            "    accuracy                           0.87      1607\n",
            "   macro avg       0.87      0.88      0.86      1607\n",
            "weighted avg       0.90      0.87      0.87      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 step 39 ave_loss 0.0198\n",
            "Epoch 3 step 79 ave_loss 0.0169\n",
            "Epoch 3 step 119 ave_loss 0.0136\n",
            "Epoch 3 step 159 ave_loss 0.0336\n",
            "Epoch 3 step 199 ave_loss 0.0075\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.93      1.00      0.96       409\n",
            "          3C       0.86      0.98      0.92       367\n",
            "          4C       1.00      0.91      0.95       831\n",
            "\n",
            "    accuracy                           0.95      1607\n",
            "   macro avg       0.93      0.96      0.94      1607\n",
            "weighted avg       0.95      0.95      0.95      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 step 39 ave_loss 0.0105\n",
            "Epoch 4 step 79 ave_loss 0.0271\n",
            "Epoch 4 step 119 ave_loss 0.0222\n",
            "Epoch 4 step 159 ave_loss 0.0229\n",
            "Epoch 4 step 199 ave_loss 0.0326\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.85      0.91      0.88       409\n",
            "          3C       0.73      0.97      0.83       367\n",
            "          4C       1.00      0.82      0.90       831\n",
            "\n",
            "    accuracy                           0.88      1607\n",
            "   macro avg       0.86      0.90      0.87      1607\n",
            "weighted avg       0.90      0.88      0.88      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 step 39 ave_loss 0.0600\n",
            "Epoch 5 step 79 ave_loss 0.0235\n",
            "Epoch 5 step 119 ave_loss 0.0038\n",
            "Epoch 5 step 159 ave_loss 0.0029\n",
            "Epoch 5 step 199 ave_loss 0.0118\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.82      0.90      0.86       409\n",
            "          3C       0.67      0.92      0.78       367\n",
            "          4C       0.98      0.77      0.86       831\n",
            "\n",
            "    accuracy                           0.84      1607\n",
            "   macro avg       0.82      0.86      0.83      1607\n",
            "weighted avg       0.87      0.84      0.84      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 step 39 ave_loss 0.0154\n",
            "Epoch 6 step 79 ave_loss 0.0134\n",
            "Epoch 6 step 119 ave_loss 0.0121\n",
            "Epoch 6 step 159 ave_loss 0.0009\n",
            "Epoch 6 step 199 ave_loss 0.0002\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.88      0.95      0.91       409\n",
            "          3C       0.86      0.99      0.92       367\n",
            "          4C       1.00      0.90      0.94       831\n",
            "\n",
            "    accuracy                           0.93      1607\n",
            "   macro avg       0.91      0.95      0.93      1607\n",
            "weighted avg       0.94      0.93      0.93      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 step 39 ave_loss 0.0001\n",
            "Epoch 7 step 79 ave_loss 0.0000\n",
            "Epoch 7 step 119 ave_loss 0.0188\n",
            "Epoch 7 step 159 ave_loss 0.0043\n",
            "Epoch 7 step 199 ave_loss 0.0031\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.90      0.99      0.94       409\n",
            "          3C       0.98      0.97      0.97       367\n",
            "          4C       1.00      0.95      0.98       831\n",
            "\n",
            "    accuracy                           0.97      1607\n",
            "   macro avg       0.96      0.97      0.96      1607\n",
            "weighted avg       0.97      0.97      0.97      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 step 39 ave_loss 0.0263\n",
            "Epoch 8 step 79 ave_loss 0.0077\n",
            "Epoch 8 step 119 ave_loss 0.0033\n",
            "Epoch 8 step 159 ave_loss 0.0006\n",
            "Epoch 8 step 199 ave_loss 0.0001\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.92      0.93      0.93       409\n",
            "          3C       0.84      0.96      0.89       367\n",
            "          4C       1.00      0.93      0.96       831\n",
            "\n",
            "    accuracy                           0.94      1607\n",
            "   macro avg       0.92      0.94      0.93      1607\n",
            "weighted avg       0.94      0.94      0.94      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 step 39 ave_loss 0.0000\n",
            "Epoch 9 step 79 ave_loss 0.0002\n",
            "Epoch 9 step 119 ave_loss 0.0000\n",
            "Epoch 9 step 159 ave_loss 0.0000\n",
            "Epoch 9 step 199 ave_loss 0.0001\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.92      0.95      0.94       409\n",
            "          3C       0.90      0.94      0.92       367\n",
            "          4C       1.00      0.96      0.98       831\n",
            "\n",
            "    accuracy                           0.96      1607\n",
            "   macro avg       0.94      0.95      0.95      1607\n",
            "weighted avg       0.96      0.96      0.96      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 step 39 ave_loss 0.0001\n",
            "Epoch 10 step 79 ave_loss 0.0000\n",
            "Epoch 10 step 119 ave_loss 0.0000\n",
            "Epoch 10 step 159 ave_loss 0.0000\n",
            "Epoch 10 step 199 ave_loss 0.0000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.94      0.94      0.94       409\n",
            "          3C       0.88      0.96      0.92       367\n",
            "          4C       1.00      0.96      0.98       831\n",
            "\n",
            "    accuracy                           0.96      1607\n",
            "   macro avg       0.94      0.95      0.95      1607\n",
            "weighted avg       0.96      0.96      0.96      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 step 39 ave_loss 0.0000\n",
            "Epoch 11 step 79 ave_loss 0.0000\n",
            "Epoch 11 step 119 ave_loss 0.0000\n",
            "Epoch 11 step 159 ave_loss 0.0000\n",
            "Epoch 11 step 199 ave_loss 0.0000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.95      0.94      0.94       409\n",
            "          3C       0.89      0.96      0.92       367\n",
            "          4C       1.00      0.97      0.98       831\n",
            "\n",
            "    accuracy                           0.96      1607\n",
            "   macro avg       0.95      0.96      0.95      1607\n",
            "weighted avg       0.96      0.96      0.96      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 step 39 ave_loss 0.0000\n",
            "Epoch 12 step 79 ave_loss 0.0000\n",
            "Epoch 12 step 119 ave_loss 0.0000\n",
            "Epoch 12 step 159 ave_loss 0.0000\n",
            "Epoch 12 step 199 ave_loss 0.0000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.95      0.94      0.94       409\n",
            "          3C       0.88      0.96      0.92       367\n",
            "          4C       1.00      0.97      0.98       831\n",
            "\n",
            "    accuracy                           0.96      1607\n",
            "   macro avg       0.95      0.96      0.95      1607\n",
            "weighted avg       0.96      0.96      0.96      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 step 39 ave_loss 0.0000\n",
            "Epoch 13 step 79 ave_loss 0.0000\n",
            "Epoch 13 step 119 ave_loss 0.0000\n",
            "Epoch 13 step 159 ave_loss 0.0000\n",
            "Epoch 13 step 199 ave_loss 0.0000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.95      0.94      0.95       409\n",
            "          3C       0.89      0.96      0.93       367\n",
            "          4C       1.00      0.97      0.98       831\n",
            "\n",
            "    accuracy                           0.96      1607\n",
            "   macro avg       0.95      0.96      0.95      1607\n",
            "weighted avg       0.96      0.96      0.96      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 step 39 ave_loss 0.0000\n",
            "Epoch 14 step 79 ave_loss 0.0000\n",
            "Epoch 14 step 119 ave_loss 0.0000\n",
            "Epoch 14 step 159 ave_loss 0.0000\n",
            "Epoch 14 step 199 ave_loss 0.0001\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.95      0.94      0.94       409\n",
            "          3C       0.89      0.96      0.92       367\n",
            "          4C       1.00      0.97      0.98       831\n",
            "\n",
            "    accuracy                           0.96      1607\n",
            "   macro avg       0.95      0.96      0.95      1607\n",
            "weighted avg       0.96      0.96      0.96      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 step 39 ave_loss 0.0000\n",
            "Epoch 15 step 79 ave_loss 0.0000\n",
            "Epoch 15 step 119 ave_loss 0.0000\n",
            "Epoch 15 step 159 ave_loss 0.0000\n",
            "Epoch 15 step 199 ave_loss 0.0001\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.95      0.94      0.95       409\n",
            "          3C       0.89      0.96      0.93       367\n",
            "          4C       1.00      0.97      0.98       831\n",
            "\n",
            "    accuracy                           0.96      1607\n",
            "   macro avg       0.95      0.96      0.95      1607\n",
            "weighted avg       0.96      0.96      0.96      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 step 39 ave_loss 0.0000\n",
            "Epoch 16 step 79 ave_loss 0.0001\n",
            "Epoch 16 step 119 ave_loss 0.0000\n",
            "Epoch 16 step 159 ave_loss 0.0001\n",
            "Epoch 16 step 199 ave_loss 0.0000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.96      0.94      0.95       409\n",
            "          3C       0.90      0.96      0.93       367\n",
            "          4C       1.00      0.98      0.99       831\n",
            "\n",
            "    accuracy                           0.97      1607\n",
            "   macro avg       0.95      0.96      0.96      1607\n",
            "weighted avg       0.97      0.97      0.97      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 step 39 ave_loss 0.0000\n",
            "Epoch 17 step 79 ave_loss 0.0000\n",
            "Epoch 17 step 119 ave_loss 0.0000\n",
            "Epoch 17 step 159 ave_loss 0.0000\n",
            "Epoch 17 step 199 ave_loss 0.0000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.96      0.94      0.95       409\n",
            "          3C       0.90      0.96      0.93       367\n",
            "          4C       1.00      0.98      0.99       831\n",
            "\n",
            "    accuracy                           0.96      1607\n",
            "   macro avg       0.95      0.96      0.96      1607\n",
            "weighted avg       0.97      0.96      0.96      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 step 39 ave_loss 0.0000\n",
            "Epoch 18 step 79 ave_loss 0.0000\n",
            "Epoch 18 step 119 ave_loss 0.0000\n",
            "Epoch 18 step 159 ave_loss 0.0000\n",
            "Epoch 18 step 199 ave_loss 0.0003\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.85      0.94      0.90       409\n",
            "          3C       0.90      0.96      0.93       367\n",
            "          4C       1.00      0.91      0.96       831\n",
            "\n",
            "    accuracy                           0.93      1607\n",
            "   macro avg       0.92      0.94      0.93      1607\n",
            "weighted avg       0.94      0.93      0.93      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 step 39 ave_loss 0.0004\n",
            "Epoch 19 step 79 ave_loss 0.0000\n",
            "Epoch 19 step 119 ave_loss 0.0000\n",
            "Epoch 19 step 159 ave_loss 0.0000\n",
            "Epoch 19 step 199 ave_loss 0.0000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.95      0.94      0.95       409\n",
            "          3C       0.90      0.96      0.93       367\n",
            "          4C       1.00      0.97      0.99       831\n",
            "\n",
            "    accuracy                           0.96      1607\n",
            "   macro avg       0.95      0.96      0.96      1607\n",
            "weighted avg       0.97      0.96      0.96      1607\n",
            "\n",
            "model: vgg16 , size: 224 , augmentation: None\n",
            "accr:  [65, 84, 86, 94, 87, 83, 93, 96, 93, 95, 95, 95, 95, 96, 95, 96, 96, 96, 93, 96]\n",
            "loss:  [0.3448, 0.0063, 0.0001, 0.0406, 0.0, 0.0911, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0002, 0.0]\n",
            "Compose(\n",
            "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=None)\n",
            "    ToTensor()\n",
            ") Compose(\n",
            "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=None)\n",
            "    ToTensor()\n",
            ")\n",
            "image size:  torch.Size([3, 224, 224])\n",
            "device: cuda\n",
            "model: resnet18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------\n",
            "Epoch 0 step 39 ave_loss 1.0034\n",
            "Epoch 0 step 79 ave_loss 0.3783\n",
            "Epoch 0 step 119 ave_loss 0.1227\n",
            "Epoch 0 step 159 ave_loss 0.0491\n",
            "Epoch 0 step 199 ave_loss 0.0262\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.86      0.76      0.80       409\n",
            "          3C       0.74      0.94      0.83       367\n",
            "          4C       1.00      0.94      0.97       831\n",
            "\n",
            "    accuracy                           0.89      1607\n",
            "   macro avg       0.87      0.88      0.87      1607\n",
            "weighted avg       0.90      0.89      0.89      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 step 39 ave_loss 0.0226\n",
            "Epoch 1 step 79 ave_loss 0.0049\n",
            "Epoch 1 step 119 ave_loss 0.0045\n",
            "Epoch 1 step 159 ave_loss 0.0030\n",
            "Epoch 1 step 199 ave_loss 0.0029\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.78      0.84      0.81       409\n",
            "          3C       0.82      0.76      0.79       367\n",
            "          4C       0.97      0.97      0.97       831\n",
            "\n",
            "    accuracy                           0.89      1607\n",
            "   macro avg       0.86      0.86      0.86      1607\n",
            "weighted avg       0.89      0.89      0.89      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 step 39 ave_loss 0.0014\n",
            "Epoch 2 step 79 ave_loss 0.0053\n",
            "Epoch 2 step 119 ave_loss 0.0027\n",
            "Epoch 2 step 159 ave_loss 0.0006\n",
            "Epoch 2 step 199 ave_loss 0.0005\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.80      0.80      0.80       409\n",
            "          3C       0.78      0.86      0.82       367\n",
            "          4C       1.00      0.96      0.98       831\n",
            "\n",
            "    accuracy                           0.89      1607\n",
            "   macro avg       0.86      0.87      0.87      1607\n",
            "weighted avg       0.90      0.89      0.90      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 step 39 ave_loss 0.0005\n",
            "Epoch 3 step 79 ave_loss 0.0004\n",
            "Epoch 3 step 119 ave_loss 0.0005\n",
            "Epoch 3 step 159 ave_loss 0.0002\n",
            "Epoch 3 step 199 ave_loss 0.0006\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.81      0.80      0.80       409\n",
            "          3C       0.78      0.85      0.81       367\n",
            "          4C       1.00      0.96      0.98       831\n",
            "\n",
            "    accuracy                           0.90      1607\n",
            "   macro avg       0.86      0.87      0.87      1607\n",
            "weighted avg       0.90      0.90      0.90      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 step 39 ave_loss 0.0004\n",
            "Epoch 4 step 79 ave_loss 0.0002\n",
            "Epoch 4 step 119 ave_loss 0.0003\n",
            "Epoch 4 step 159 ave_loss 0.0001\n",
            "Epoch 4 step 199 ave_loss 0.0003\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.81      0.80      0.81       409\n",
            "          3C       0.78      0.86      0.82       367\n",
            "          4C       1.00      0.96      0.98       831\n",
            "\n",
            "    accuracy                           0.90      1607\n",
            "   macro avg       0.86      0.87      0.87      1607\n",
            "weighted avg       0.90      0.90      0.90      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 step 39 ave_loss 0.0002\n",
            "Epoch 5 step 79 ave_loss 0.0001\n",
            "Epoch 5 step 119 ave_loss 0.0001\n",
            "Epoch 5 step 159 ave_loss 0.0002\n",
            "Epoch 5 step 199 ave_loss 0.0002\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.80      0.80      0.80       409\n",
            "          3C       0.78      0.84      0.81       367\n",
            "          4C       1.00      0.96      0.98       831\n",
            "\n",
            "    accuracy                           0.89      1607\n",
            "   macro avg       0.86      0.87      0.86      1607\n",
            "weighted avg       0.90      0.89      0.90      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 step 39 ave_loss 0.0003\n",
            "Epoch 6 step 79 ave_loss 0.0004\n",
            "Epoch 6 step 119 ave_loss 0.0001\n",
            "Epoch 6 step 159 ave_loss 0.0002\n",
            "Epoch 6 step 199 ave_loss 0.0001\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.82      0.79      0.81       409\n",
            "          3C       0.78      0.85      0.81       367\n",
            "          4C       1.00      0.97      0.98       831\n",
            "\n",
            "    accuracy                           0.90      1607\n",
            "   macro avg       0.86      0.87      0.87      1607\n",
            "weighted avg       0.90      0.90      0.90      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 step 39 ave_loss 0.0002\n",
            "Epoch 7 step 79 ave_loss 0.0009\n",
            "Epoch 7 step 119 ave_loss 0.0007\n",
            "Epoch 7 step 159 ave_loss 0.0001\n",
            "Epoch 7 step 199 ave_loss 0.0001\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.79      0.82      0.80       409\n",
            "          3C       0.79      0.84      0.82       367\n",
            "          4C       1.00      0.95      0.97       831\n",
            "\n",
            "    accuracy                           0.89      1607\n",
            "   macro avg       0.86      0.87      0.87      1607\n",
            "weighted avg       0.90      0.89      0.89      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 step 39 ave_loss 0.0001\n",
            "Epoch 8 step 79 ave_loss 0.0001\n",
            "Epoch 8 step 119 ave_loss 0.0004\n",
            "Epoch 8 step 159 ave_loss 0.0002\n",
            "Epoch 8 step 199 ave_loss 0.0001\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.84      0.80      0.82       409\n",
            "          3C       0.78      0.87      0.82       367\n",
            "          4C       1.00      0.97      0.98       831\n",
            "\n",
            "    accuracy                           0.90      1607\n",
            "   macro avg       0.87      0.88      0.87      1607\n",
            "weighted avg       0.91      0.90      0.90      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 step 39 ave_loss 0.0002\n",
            "Epoch 9 step 79 ave_loss 0.0001\n",
            "Epoch 9 step 119 ave_loss 0.0001\n",
            "Epoch 9 step 159 ave_loss 0.0001\n",
            "Epoch 9 step 199 ave_loss 0.0001\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.86      0.79      0.83       409\n",
            "          3C       0.78      0.88      0.83       367\n",
            "          4C       1.00      0.98      0.99       831\n",
            "\n",
            "    accuracy                           0.91      1607\n",
            "   macro avg       0.88      0.88      0.88      1607\n",
            "weighted avg       0.91      0.91      0.91      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 step 39 ave_loss 0.0001\n",
            "Epoch 10 step 79 ave_loss 0.0002\n",
            "Epoch 10 step 119 ave_loss 0.0002\n",
            "Epoch 10 step 159 ave_loss 0.0001\n",
            "Epoch 10 step 199 ave_loss 0.0001\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.86      0.79      0.83       409\n",
            "          3C       0.78      0.90      0.84       367\n",
            "          4C       1.00      0.97      0.98       831\n",
            "\n",
            "    accuracy                           0.91      1607\n",
            "   macro avg       0.88      0.89      0.88      1607\n",
            "weighted avg       0.91      0.91      0.91      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 step 39 ave_loss 0.0001\n",
            "Epoch 11 step 79 ave_loss 0.0003\n",
            "Epoch 11 step 119 ave_loss 0.0002\n",
            "Epoch 11 step 159 ave_loss 0.0001\n",
            "Epoch 11 step 199 ave_loss 0.0002\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.82      0.82      0.82       409\n",
            "          3C       0.80      0.85      0.83       367\n",
            "          4C       1.00      0.97      0.99       831\n",
            "\n",
            "    accuracy                           0.91      1607\n",
            "   macro avg       0.87      0.88      0.88      1607\n",
            "weighted avg       0.91      0.91      0.91      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 step 39 ave_loss 0.0001\n",
            "Epoch 12 step 79 ave_loss 0.0001\n",
            "Epoch 12 step 119 ave_loss 0.0004\n",
            "Epoch 12 step 159 ave_loss 0.0001\n",
            "Epoch 12 step 199 ave_loss 0.0001\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.85      0.80      0.82       409\n",
            "          3C       0.78      0.87      0.82       367\n",
            "          4C       1.00      0.98      0.99       831\n",
            "\n",
            "    accuracy                           0.91      1607\n",
            "   macro avg       0.88      0.88      0.88      1607\n",
            "weighted avg       0.91      0.91      0.91      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 step 39 ave_loss 0.0002\n",
            "Epoch 13 step 79 ave_loss 0.0002\n",
            "Epoch 13 step 119 ave_loss 0.0002\n",
            "Epoch 13 step 159 ave_loss 0.0001\n",
            "Epoch 13 step 199 ave_loss 0.0001\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.89      0.79      0.84       409\n",
            "          3C       0.79      0.91      0.84       367\n",
            "          4C       1.00      0.98      0.99       831\n",
            "\n",
            "    accuracy                           0.92      1607\n",
            "   macro avg       0.89      0.89      0.89      1607\n",
            "weighted avg       0.92      0.92      0.92      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 step 39 ave_loss 0.0001\n",
            "Epoch 14 step 79 ave_loss 0.0002\n",
            "Epoch 14 step 119 ave_loss 0.0002\n",
            "Epoch 14 step 159 ave_loss 0.0001\n",
            "Epoch 14 step 199 ave_loss 0.0001\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.86      0.80      0.83       409\n",
            "          3C       0.78      0.88      0.83       367\n",
            "          4C       1.00      0.98      0.99       831\n",
            "\n",
            "    accuracy                           0.91      1607\n",
            "   macro avg       0.88      0.89      0.88      1607\n",
            "weighted avg       0.91      0.91      0.91      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 step 39 ave_loss 0.0001\n",
            "Epoch 15 step 79 ave_loss 0.0001\n",
            "Epoch 15 step 119 ave_loss 0.0002\n",
            "Epoch 15 step 159 ave_loss 0.0001\n",
            "Epoch 15 step 199 ave_loss 0.0002\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.85      0.81      0.83       409\n",
            "          3C       0.79      0.85      0.82       367\n",
            "          4C       1.00      0.99      0.99       831\n",
            "\n",
            "    accuracy                           0.91      1607\n",
            "   macro avg       0.88      0.88      0.88      1607\n",
            "weighted avg       0.91      0.91      0.91      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 step 39 ave_loss 0.0001\n",
            "Epoch 16 step 79 ave_loss 0.0001\n",
            "Epoch 16 step 119 ave_loss 0.0001\n",
            "Epoch 16 step 159 ave_loss 0.0001\n",
            "Epoch 16 step 199 ave_loss 0.0001\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.84      0.80      0.82       409\n",
            "          3C       0.78      0.85      0.82       367\n",
            "          4C       1.00      0.98      0.99       831\n",
            "\n",
            "    accuracy                           0.91      1607\n",
            "   macro avg       0.87      0.88      0.88      1607\n",
            "weighted avg       0.91      0.91      0.91      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 step 39 ave_loss 0.0002\n",
            "Epoch 17 step 79 ave_loss 0.0002\n",
            "Epoch 17 step 119 ave_loss 0.0001\n",
            "Epoch 17 step 159 ave_loss 0.0003\n",
            "Epoch 17 step 199 ave_loss 0.0002\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.87      0.79      0.83       409\n",
            "          3C       0.78      0.90      0.83       367\n",
            "          4C       1.00      0.97      0.99       831\n",
            "\n",
            "    accuracy                           0.91      1607\n",
            "   macro avg       0.88      0.89      0.88      1607\n",
            "weighted avg       0.91      0.91      0.91      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 step 39 ave_loss 0.0002\n",
            "Epoch 18 step 79 ave_loss 0.0001\n",
            "Epoch 18 step 119 ave_loss 0.0004\n",
            "Epoch 18 step 159 ave_loss 0.0002\n",
            "Epoch 18 step 199 ave_loss 0.0001\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.84      0.80      0.82       409\n",
            "          3C       0.78      0.85      0.82       367\n",
            "          4C       1.00      0.98      0.99       831\n",
            "\n",
            "    accuracy                           0.91      1607\n",
            "   macro avg       0.87      0.88      0.87      1607\n",
            "weighted avg       0.91      0.91      0.91      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 step 39 ave_loss 0.0002\n",
            "Epoch 19 step 79 ave_loss 0.0002\n",
            "Epoch 19 step 119 ave_loss 0.0001\n",
            "Epoch 19 step 159 ave_loss 0.0001\n",
            "Epoch 19 step 199 ave_loss 0.0001\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.84      0.80      0.82       409\n",
            "          3C       0.79      0.85      0.82       367\n",
            "          4C       1.00      0.98      0.99       831\n",
            "\n",
            "    accuracy                           0.91      1607\n",
            "   macro avg       0.87      0.88      0.88      1607\n",
            "weighted avg       0.91      0.91      0.91      1607\n",
            "\n",
            "model: resnet18 , size: 224 , augmentation: None\n",
            "accr:  [89, 88, 89, 89, 89, 89, 89, 89, 90, 91, 90, 90, 90, 91, 91, 90, 90, 90, 90, 90]\n",
            "loss:  [0.0004, 0.0047, 0.0001, 0.0008, 0.0, 0.0001, 0.0001, 0.0001, 0.0, 0.0001, 0.0009, 0.0008, 0.0001, 0.0, 0.0003, 0.0001, 0.0001, 0.0002, 0.0, 0.0001]\n",
            "Compose(\n",
            "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=None)\n",
            "    ToTensor()\n",
            ") Compose(\n",
            "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=None)\n",
            "    ToTensor()\n",
            ")\n",
            "image size:  torch.Size([3, 224, 224])\n",
            "device: cuda\n",
            "model: resnet50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------\n",
            "Epoch 0 step 39 ave_loss 3.5563\n",
            "Epoch 0 step 79 ave_loss 1.3559\n",
            "Epoch 0 step 119 ave_loss 1.0707\n",
            "Epoch 0 step 159 ave_loss 0.9375\n",
            "Epoch 0 step 199 ave_loss 0.8439\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.35      0.99      0.51       409\n",
            "          3C       0.00      0.00      0.00       367\n",
            "          4C       0.79      0.42      0.55       831\n",
            "\n",
            "    accuracy                           0.47      1607\n",
            "   macro avg       0.38      0.47      0.35      1607\n",
            "weighted avg       0.50      0.47      0.42      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 step 39 ave_loss 0.4085\n",
            "Epoch 1 step 79 ave_loss 0.3995\n",
            "Epoch 1 step 119 ave_loss 0.3186\n",
            "Epoch 1 step 159 ave_loss 0.1614\n",
            "Epoch 1 step 199 ave_loss 0.1232\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.57      0.67      0.62       409\n",
            "          3C       0.57      0.92      0.71       367\n",
            "          4C       0.97      0.62      0.76       831\n",
            "\n",
            "    accuracy                           0.70      1607\n",
            "   macro avg       0.70      0.74      0.69      1607\n",
            "weighted avg       0.78      0.70      0.71      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 step 39 ave_loss 0.0298\n",
            "Epoch 2 step 79 ave_loss 0.0224\n",
            "Epoch 2 step 119 ave_loss 0.0494\n",
            "Epoch 2 step 159 ave_loss 0.0148\n",
            "Epoch 2 step 199 ave_loss 0.0428\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.72      0.76      0.74       409\n",
            "          3C       0.62      0.61      0.62       367\n",
            "          4C       0.89      0.87      0.88       831\n",
            "\n",
            "    accuracy                           0.78      1607\n",
            "   macro avg       0.74      0.75      0.75      1607\n",
            "weighted avg       0.79      0.78      0.79      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 step 39 ave_loss 0.0461\n",
            "Epoch 3 step 79 ave_loss 0.0611\n",
            "Epoch 3 step 119 ave_loss 0.0647\n",
            "Epoch 3 step 159 ave_loss 0.0294\n",
            "Epoch 3 step 199 ave_loss 0.1326\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.80      0.71      0.75       409\n",
            "          3C       0.83      0.93      0.87       367\n",
            "          4C       0.94      0.94      0.94       831\n",
            "\n",
            "    accuracy                           0.88      1607\n",
            "   macro avg       0.86      0.86      0.86      1607\n",
            "weighted avg       0.88      0.88      0.88      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 step 39 ave_loss 0.1130\n",
            "Epoch 4 step 79 ave_loss 0.0288\n",
            "Epoch 4 step 119 ave_loss 0.0299\n",
            "Epoch 4 step 159 ave_loss 0.0173\n",
            "Epoch 4 step 199 ave_loss 0.0144\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.72      0.78      0.75       409\n",
            "          3C       0.69      0.85      0.76       367\n",
            "          4C       0.99      0.84      0.91       831\n",
            "\n",
            "    accuracy                           0.83      1607\n",
            "   macro avg       0.80      0.83      0.81      1607\n",
            "weighted avg       0.85      0.83      0.84      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 step 39 ave_loss 0.0254\n",
            "Epoch 5 step 79 ave_loss 0.0237\n",
            "Epoch 5 step 119 ave_loss 0.0188\n",
            "Epoch 5 step 159 ave_loss 0.0043\n",
            "Epoch 5 step 199 ave_loss 0.0011\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.83      0.81      0.82       409\n",
            "          3C       0.72      0.95      0.82       367\n",
            "          4C       1.00      0.87      0.93       831\n",
            "\n",
            "    accuracy                           0.87      1607\n",
            "   macro avg       0.85      0.88      0.86      1607\n",
            "weighted avg       0.89      0.87      0.88      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 step 39 ave_loss 0.0018\n",
            "Epoch 6 step 79 ave_loss 0.0006\n",
            "Epoch 6 step 119 ave_loss 0.0004\n",
            "Epoch 6 step 159 ave_loss 0.0007\n",
            "Epoch 6 step 199 ave_loss 0.0003\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.86      0.81      0.84       409\n",
            "          3C       0.69      0.94      0.80       367\n",
            "          4C       1.00      0.87      0.93       831\n",
            "\n",
            "    accuracy                           0.87      1607\n",
            "   macro avg       0.85      0.87      0.86      1607\n",
            "weighted avg       0.90      0.87      0.88      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 step 39 ave_loss 0.0007\n",
            "Epoch 7 step 79 ave_loss 0.0011\n",
            "Epoch 7 step 119 ave_loss 0.0027\n",
            "Epoch 7 step 159 ave_loss 0.0044\n",
            "Epoch 7 step 199 ave_loss 0.0018\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.84      0.80      0.82       409\n",
            "          3C       0.68      0.95      0.79       367\n",
            "          4C       1.00      0.85      0.92       831\n",
            "\n",
            "    accuracy                           0.86      1607\n",
            "   macro avg       0.84      0.87      0.85      1607\n",
            "weighted avg       0.89      0.86      0.87      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 step 39 ave_loss 0.0002\n",
            "Epoch 8 step 79 ave_loss 0.0002\n",
            "Epoch 8 step 119 ave_loss 0.0006\n",
            "Epoch 8 step 159 ave_loss 0.0006\n",
            "Epoch 8 step 199 ave_loss 0.0009\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.85      0.80      0.83       409\n",
            "          3C       0.69      0.92      0.79       367\n",
            "          4C       0.99      0.88      0.93       831\n",
            "\n",
            "    accuracy                           0.87      1607\n",
            "   macro avg       0.85      0.87      0.85      1607\n",
            "weighted avg       0.89      0.87      0.87      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 step 39 ave_loss 0.0001\n",
            "Epoch 9 step 79 ave_loss 0.0006\n",
            "Epoch 9 step 119 ave_loss 0.0002\n",
            "Epoch 9 step 159 ave_loss 0.0001\n",
            "Epoch 9 step 199 ave_loss 0.0001\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.86      0.80      0.83       409\n",
            "          3C       0.69      0.93      0.79       367\n",
            "          4C       1.00      0.88      0.93       831\n",
            "\n",
            "    accuracy                           0.87      1607\n",
            "   macro avg       0.85      0.87      0.85      1607\n",
            "weighted avg       0.89      0.87      0.87      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 step 39 ave_loss 0.0001\n",
            "Epoch 10 step 79 ave_loss 0.0001\n",
            "Epoch 10 step 119 ave_loss 0.0001\n",
            "Epoch 10 step 159 ave_loss 0.0001\n",
            "Epoch 10 step 199 ave_loss 0.0001\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.87      0.79      0.83       409\n",
            "          3C       0.69      0.96      0.80       367\n",
            "          4C       1.00      0.87      0.93       831\n",
            "\n",
            "    accuracy                           0.87      1607\n",
            "   macro avg       0.85      0.87      0.85      1607\n",
            "weighted avg       0.89      0.87      0.87      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 step 39 ave_loss 0.0002\n",
            "Epoch 11 step 79 ave_loss 0.0030\n",
            "Epoch 11 step 119 ave_loss 0.0012\n",
            "Epoch 11 step 159 ave_loss 0.0010\n",
            "Epoch 11 step 199 ave_loss 0.0004\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.87      0.80      0.83       409\n",
            "          3C       0.81      0.96      0.88       367\n",
            "          4C       0.99      0.94      0.97       831\n",
            "\n",
            "    accuracy                           0.91      1607\n",
            "   macro avg       0.89      0.90      0.89      1607\n",
            "weighted avg       0.92      0.91      0.91      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 step 39 ave_loss 0.0002\n",
            "Epoch 12 step 79 ave_loss 0.0006\n",
            "Epoch 12 step 119 ave_loss 0.0000\n",
            "Epoch 12 step 159 ave_loss 0.0000\n",
            "Epoch 12 step 199 ave_loss 0.0002\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.83      0.81      0.82       409\n",
            "          3C       0.76      0.94      0.84       367\n",
            "          4C       1.00      0.90      0.95       831\n",
            "\n",
            "    accuracy                           0.89      1607\n",
            "   macro avg       0.86      0.89      0.87      1607\n",
            "weighted avg       0.90      0.89      0.89      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 step 39 ave_loss 0.0006\n",
            "Epoch 13 step 79 ave_loss 0.0020\n",
            "Epoch 13 step 119 ave_loss 0.0004\n",
            "Epoch 13 step 159 ave_loss 0.0002\n",
            "Epoch 13 step 199 ave_loss 0.0003\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.89      0.79      0.84       409\n",
            "          3C       0.72      0.98      0.83       367\n",
            "          4C       1.00      0.90      0.95       831\n",
            "\n",
            "    accuracy                           0.89      1607\n",
            "   macro avg       0.87      0.89      0.87      1607\n",
            "weighted avg       0.91      0.89      0.89      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 step 39 ave_loss 0.0005\n",
            "Epoch 14 step 79 ave_loss 0.0002\n",
            "Epoch 14 step 119 ave_loss 0.0003\n",
            "Epoch 14 step 159 ave_loss 0.0001\n",
            "Epoch 14 step 199 ave_loss 0.0001\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.88      0.80      0.84       409\n",
            "          3C       0.73      0.95      0.82       367\n",
            "          4C       1.00      0.90      0.95       831\n",
            "\n",
            "    accuracy                           0.89      1607\n",
            "   macro avg       0.87      0.89      0.87      1607\n",
            "weighted avg       0.91      0.89      0.89      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 step 39 ave_loss 0.0001\n",
            "Epoch 15 step 79 ave_loss 0.0001\n",
            "Epoch 15 step 119 ave_loss 0.0001\n",
            "Epoch 15 step 159 ave_loss 0.0001\n",
            "Epoch 15 step 199 ave_loss 0.0001\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.87      0.78      0.82       409\n",
            "          3C       0.71      0.97      0.82       367\n",
            "          4C       1.00      0.88      0.94       831\n",
            "\n",
            "    accuracy                           0.88      1607\n",
            "   macro avg       0.86      0.88      0.86      1607\n",
            "weighted avg       0.90      0.88      0.88      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 step 39 ave_loss 0.0002\n",
            "Epoch 16 step 79 ave_loss 0.0000\n",
            "Epoch 16 step 119 ave_loss 0.0002\n",
            "Epoch 16 step 159 ave_loss 0.0000\n",
            "Epoch 16 step 199 ave_loss 0.0000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.81      0.80      0.80       409\n",
            "          3C       0.71      0.94      0.81       367\n",
            "          4C       1.00      0.86      0.92       831\n",
            "\n",
            "    accuracy                           0.86      1607\n",
            "   macro avg       0.84      0.87      0.84      1607\n",
            "weighted avg       0.88      0.86      0.87      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 step 39 ave_loss 0.0001\n",
            "Epoch 17 step 79 ave_loss 0.0001\n",
            "Epoch 17 step 119 ave_loss 0.0002\n",
            "Epoch 17 step 159 ave_loss 0.0001\n",
            "Epoch 17 step 199 ave_loss 0.0000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.85      0.80      0.82       409\n",
            "          3C       0.73      0.97      0.83       367\n",
            "          4C       1.00      0.89      0.94       831\n",
            "\n",
            "    accuracy                           0.88      1607\n",
            "   macro avg       0.86      0.88      0.86      1607\n",
            "weighted avg       0.90      0.88      0.89      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 step 39 ave_loss 0.0000\n",
            "Epoch 18 step 79 ave_loss 0.0001\n",
            "Epoch 18 step 119 ave_loss 0.0000\n",
            "Epoch 18 step 159 ave_loss 0.0001\n",
            "Epoch 18 step 199 ave_loss 0.0001\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.84      0.80      0.82       409\n",
            "          3C       0.72      0.94      0.81       367\n",
            "          4C       0.99      0.88      0.93       831\n",
            "\n",
            "    accuracy                           0.87      1607\n",
            "   macro avg       0.85      0.87      0.86      1607\n",
            "weighted avg       0.89      0.87      0.88      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 step 39 ave_loss 0.0002\n",
            "Epoch 19 step 79 ave_loss 0.0001\n",
            "Epoch 19 step 119 ave_loss 0.0000\n",
            "Epoch 19 step 159 ave_loss 0.0000\n",
            "Epoch 19 step 199 ave_loss 0.0000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.81      0.80      0.81       409\n",
            "          3C       0.70      0.95      0.81       367\n",
            "          4C       1.00      0.85      0.92       831\n",
            "\n",
            "    accuracy                           0.86      1607\n",
            "   macro avg       0.84      0.87      0.84      1607\n",
            "weighted avg       0.88      0.86      0.86      1607\n",
            "\n",
            "model: resnet50 , size: 224 , augmentation: None\n",
            "accr:  [46, 70, 78, 88, 82, 87, 87, 86, 86, 86, 86, 91, 88, 88, 88, 87, 86, 88, 87, 85]\n",
            "loss:  [0.4673, 0.0037, 0.003, 0.517, 0.0085, 0.0001, 0.0, 0.0003, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001, 0.0, 0.0]\n",
            "Compose(\n",
            "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=None)\n",
            "    ToTensor()\n",
            ") Compose(\n",
            "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=None)\n",
            "    ToTensor()\n",
            ")\n",
            "image size:  torch.Size([3, 224, 224])\n",
            "device: cuda\n",
            "model: densenet121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------\n",
            "Epoch 0 step 39 ave_loss 0.9583\n",
            "Epoch 0 step 79 ave_loss 0.5300\n",
            "Epoch 0 step 119 ave_loss 0.3642\n",
            "Epoch 0 step 159 ave_loss 0.1736\n",
            "Epoch 0 step 199 ave_loss 0.0888\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.90      0.87      0.88       409\n",
            "          3C       0.79      0.92      0.85       367\n",
            "          4C       1.00      0.94      0.97       831\n",
            "\n",
            "    accuracy                           0.92      1607\n",
            "   macro avg       0.89      0.91      0.90      1607\n",
            "weighted avg       0.92      0.92      0.92      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 step 39 ave_loss 0.0714\n",
            "Epoch 1 step 79 ave_loss 0.0678\n",
            "Epoch 1 step 119 ave_loss 0.0222\n",
            "Epoch 1 step 159 ave_loss 0.0080\n",
            "Epoch 1 step 199 ave_loss 0.0146\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.86      0.78      0.81       409\n",
            "          3C       0.48      0.87      0.62       367\n",
            "          4C       1.00      0.68      0.81       831\n",
            "\n",
            "    accuracy                           0.75      1607\n",
            "   macro avg       0.78      0.78      0.75      1607\n",
            "weighted avg       0.84      0.75      0.77      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 step 39 ave_loss 0.0060\n",
            "Epoch 2 step 79 ave_loss 0.0062\n",
            "Epoch 2 step 119 ave_loss 0.0076\n",
            "Epoch 2 step 159 ave_loss 0.0019\n",
            "Epoch 2 step 199 ave_loss 0.0015\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.78      0.81      0.80       409\n",
            "          3C       0.61      0.88      0.72       367\n",
            "          4C       1.00      0.78      0.88       831\n",
            "\n",
            "    accuracy                           0.81      1607\n",
            "   macro avg       0.80      0.83      0.80      1607\n",
            "weighted avg       0.85      0.81      0.82      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 step 39 ave_loss 0.0009\n",
            "Epoch 3 step 79 ave_loss 0.0012\n",
            "Epoch 3 step 119 ave_loss 0.0010\n",
            "Epoch 3 step 159 ave_loss 0.0006\n",
            "Epoch 3 step 199 ave_loss 0.0007\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.84      0.81      0.82       409\n",
            "          3C       0.70      0.91      0.79       367\n",
            "          4C       1.00      0.88      0.94       831\n",
            "\n",
            "    accuracy                           0.87      1607\n",
            "   macro avg       0.84      0.87      0.85      1607\n",
            "weighted avg       0.89      0.87      0.87      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 step 39 ave_loss 0.0009\n",
            "Epoch 4 step 79 ave_loss 0.0029\n",
            "Epoch 4 step 119 ave_loss 0.0014\n",
            "Epoch 4 step 159 ave_loss 0.0013\n",
            "Epoch 4 step 199 ave_loss 0.0010\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.87      0.79      0.83       409\n",
            "          3C       0.67      0.95      0.79       367\n",
            "          4C       1.00      0.86      0.92       831\n",
            "\n",
            "    accuracy                           0.86      1607\n",
            "   macro avg       0.85      0.87      0.85      1607\n",
            "weighted avg       0.89      0.86      0.87      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 step 39 ave_loss 0.0007\n",
            "Epoch 5 step 79 ave_loss 0.0006\n",
            "Epoch 5 step 119 ave_loss 0.0004\n",
            "Epoch 5 step 159 ave_loss 0.0007\n",
            "Epoch 5 step 199 ave_loss 0.0009\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.92      0.80      0.86       409\n",
            "          3C       0.67      0.96      0.79       367\n",
            "          4C       1.00      0.87      0.93       831\n",
            "\n",
            "    accuracy                           0.87      1607\n",
            "   macro avg       0.86      0.88      0.86      1607\n",
            "weighted avg       0.90      0.87      0.88      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 step 39 ave_loss 0.0006\n",
            "Epoch 6 step 79 ave_loss 0.0004\n",
            "Epoch 6 step 119 ave_loss 0.0004\n",
            "Epoch 6 step 159 ave_loss 0.0015\n",
            "Epoch 6 step 199 ave_loss 0.0004\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.90      0.80      0.85       409\n",
            "          3C       0.73      0.96      0.83       367\n",
            "          4C       0.99      0.91      0.95       831\n",
            "\n",
            "    accuracy                           0.89      1607\n",
            "   macro avg       0.87      0.89      0.88      1607\n",
            "weighted avg       0.91      0.89      0.90      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 step 39 ave_loss 0.0004\n",
            "Epoch 7 step 79 ave_loss 0.0004\n",
            "Epoch 7 step 119 ave_loss 0.0007\n",
            "Epoch 7 step 159 ave_loss 0.0006\n",
            "Epoch 7 step 199 ave_loss 0.0004\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.88      0.81      0.85       409\n",
            "          3C       0.72      0.95      0.82       367\n",
            "          4C       1.00      0.90      0.95       831\n",
            "\n",
            "    accuracy                           0.89      1607\n",
            "   macro avg       0.87      0.89      0.87      1607\n",
            "weighted avg       0.91      0.89      0.89      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 step 39 ave_loss 0.0009\n",
            "Epoch 8 step 79 ave_loss 0.0003\n",
            "Epoch 8 step 119 ave_loss 0.0004\n",
            "Epoch 8 step 159 ave_loss 0.0005\n",
            "Epoch 8 step 199 ave_loss 0.0002\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.92      0.79      0.85       409\n",
            "          3C       0.68      0.95      0.79       367\n",
            "          4C       1.00      0.89      0.94       831\n",
            "\n",
            "    accuracy                           0.88      1607\n",
            "   macro avg       0.87      0.88      0.86      1607\n",
            "weighted avg       0.91      0.88      0.89      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 step 39 ave_loss 0.0006\n",
            "Epoch 9 step 79 ave_loss 0.0003\n",
            "Epoch 9 step 119 ave_loss 0.0002\n",
            "Epoch 9 step 159 ave_loss 0.0004\n",
            "Epoch 9 step 199 ave_loss 0.0004\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.85      0.81      0.83       409\n",
            "          3C       0.71      0.90      0.79       367\n",
            "          4C       1.00      0.90      0.95       831\n",
            "\n",
            "    accuracy                           0.88      1607\n",
            "   macro avg       0.85      0.87      0.86      1607\n",
            "weighted avg       0.89      0.88      0.88      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 step 39 ave_loss 0.0005\n",
            "Epoch 10 step 79 ave_loss 0.0003\n",
            "Epoch 10 step 119 ave_loss 0.0003\n",
            "Epoch 10 step 159 ave_loss 0.0003\n",
            "Epoch 10 step 199 ave_loss 0.0003\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.85      0.81      0.83       409\n",
            "          3C       0.72      0.90      0.80       367\n",
            "          4C       1.00      0.91      0.95       831\n",
            "\n",
            "    accuracy                           0.88      1607\n",
            "   macro avg       0.85      0.87      0.86      1607\n",
            "weighted avg       0.90      0.88      0.89      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 step 39 ave_loss 0.0005\n",
            "Epoch 11 step 79 ave_loss 0.0005\n",
            "Epoch 11 step 119 ave_loss 0.0004\n",
            "Epoch 11 step 159 ave_loss 0.0005\n",
            "Epoch 11 step 199 ave_loss 0.0002\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.92      0.80      0.85       409\n",
            "          3C       0.68      0.94      0.79       367\n",
            "          4C       1.00      0.90      0.95       831\n",
            "\n",
            "    accuracy                           0.88      1607\n",
            "   macro avg       0.87      0.88      0.86      1607\n",
            "weighted avg       0.91      0.88      0.89      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 step 39 ave_loss 0.0005\n",
            "Epoch 12 step 79 ave_loss 0.0003\n",
            "Epoch 12 step 119 ave_loss 0.0004\n",
            "Epoch 12 step 159 ave_loss 0.0004\n",
            "Epoch 12 step 199 ave_loss 0.0003\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.92      0.80      0.86       409\n",
            "          3C       0.70      0.95      0.80       367\n",
            "          4C       1.00      0.90      0.95       831\n",
            "\n",
            "    accuracy                           0.89      1607\n",
            "   macro avg       0.87      0.89      0.87      1607\n",
            "weighted avg       0.91      0.89      0.89      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 step 39 ave_loss 0.0003\n",
            "Epoch 13 step 79 ave_loss 0.0003\n",
            "Epoch 13 step 119 ave_loss 0.0002\n",
            "Epoch 13 step 159 ave_loss 0.0003\n",
            "Epoch 13 step 199 ave_loss 0.0002\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.88      0.81      0.85       409\n",
            "          3C       0.72      0.91      0.80       367\n",
            "          4C       1.00      0.92      0.96       831\n",
            "\n",
            "    accuracy                           0.89      1607\n",
            "   macro avg       0.87      0.88      0.87      1607\n",
            "weighted avg       0.90      0.89      0.89      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 step 39 ave_loss 0.0004\n",
            "Epoch 14 step 79 ave_loss 0.0003\n",
            "Epoch 14 step 119 ave_loss 0.0006\n",
            "Epoch 14 step 159 ave_loss 0.0005\n",
            "Epoch 14 step 199 ave_loss 0.0004\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.91      0.81      0.86       409\n",
            "          3C       0.69      0.95      0.80       367\n",
            "          4C       1.00      0.89      0.94       831\n",
            "\n",
            "    accuracy                           0.88      1607\n",
            "   macro avg       0.87      0.88      0.86      1607\n",
            "weighted avg       0.91      0.88      0.89      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 step 39 ave_loss 0.0002\n",
            "Epoch 15 step 79 ave_loss 0.0005\n",
            "Epoch 15 step 119 ave_loss 0.0002\n",
            "Epoch 15 step 159 ave_loss 0.0009\n",
            "Epoch 15 step 199 ave_loss 0.0004\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.91      0.80      0.85       409\n",
            "          3C       0.66      0.95      0.78       367\n",
            "          4C       1.00      0.87      0.93       831\n",
            "\n",
            "    accuracy                           0.87      1607\n",
            "   macro avg       0.86      0.87      0.85      1607\n",
            "weighted avg       0.90      0.87      0.87      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 step 39 ave_loss 0.0003\n",
            "Epoch 16 step 79 ave_loss 0.0002\n",
            "Epoch 16 step 119 ave_loss 0.0003\n",
            "Epoch 16 step 159 ave_loss 0.0005\n",
            "Epoch 16 step 199 ave_loss 0.0003\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.90      0.81      0.85       409\n",
            "          3C       0.66      0.94      0.77       367\n",
            "          4C       1.00      0.86      0.92       831\n",
            "\n",
            "    accuracy                           0.86      1607\n",
            "   macro avg       0.85      0.87      0.85      1607\n",
            "weighted avg       0.90      0.86      0.87      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 step 39 ave_loss 0.0004\n",
            "Epoch 17 step 79 ave_loss 0.0004\n",
            "Epoch 17 step 119 ave_loss 0.0004\n",
            "Epoch 17 step 159 ave_loss 0.0003\n",
            "Epoch 17 step 199 ave_loss 0.0005\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.90      0.80      0.85       409\n",
            "          3C       0.68      0.96      0.80       367\n",
            "          4C       1.00      0.88      0.93       831\n",
            "\n",
            "    accuracy                           0.88      1607\n",
            "   macro avg       0.86      0.88      0.86      1607\n",
            "weighted avg       0.90      0.88      0.88      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 step 39 ave_loss 0.0002\n",
            "Epoch 18 step 79 ave_loss 0.0004\n",
            "Epoch 18 step 119 ave_loss 0.0003\n",
            "Epoch 18 step 159 ave_loss 0.0002\n",
            "Epoch 18 step 199 ave_loss 0.0002\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.92      0.80      0.85       409\n",
            "          3C       0.66      0.95      0.78       367\n",
            "          4C       1.00      0.87      0.93       831\n",
            "\n",
            "    accuracy                           0.87      1607\n",
            "   macro avg       0.86      0.87      0.86      1607\n",
            "weighted avg       0.90      0.87      0.88      1607\n",
            "\n",
            "---------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 step 39 ave_loss 0.0003\n",
            "Epoch 19 step 79 ave_loss 0.0004\n",
            "Epoch 19 step 119 ave_loss 0.0009\n",
            "Epoch 19 step 159 ave_loss 0.0005\n",
            "Epoch 19 step 199 ave_loss 0.0004\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.84      0.81      0.82       409\n",
            "          3C       0.66      0.90      0.76       367\n",
            "          4C       1.00      0.85      0.92       831\n",
            "\n",
            "    accuracy                           0.85      1607\n",
            "   macro avg       0.83      0.85      0.84      1607\n",
            "weighted avg       0.88      0.85      0.86      1607\n",
            "\n",
            "model: densenet121 , size: 224 , augmentation: None\n",
            "accr:  [91, 75, 81, 86, 86, 87, 89, 88, 88, 87, 88, 88, 88, 88, 88, 86, 86, 87, 87, 85]\n",
            "loss:  [0.1349, 0.0016, 0.0004, 0.0002, 0.0002, 0.0001, 0.0007, 0.0013, 0.0001, 0.0001, 0.0001, 0.0, 0.0002, 0.0002, 0.0002, 0.0001, 0.0001, 0.003, 0.0, 0.0011]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HiJeRxHTog4"
      },
      "source": [
        "## Test mô hình đã huấn luyện trên video\n",
        "  - Lấy ra toàn bộ các frame của 1 video\n",
        "  - cho các frame đã có qua mô hình đã huấn huyện -> kết quả được 1 mảng thể hiện các frame được dự đoán ở lớp nào\n",
        "  - Đếm giá trị các phân lớp, lấy giá trị phân lớp có nhiều frame được phân vào nhất làm giá trị phân lớp của video\n",
        "\n",
        "Ví dụ: Video 123 có 21 frame:\n",
        "  - 18 frame được dự đoán là lớp 2C (86%)\n",
        "  - 2 frame được dự đoán là lớp 3C (10%)\n",
        "  - 1 frame được dự đoán là lớp 4C (4%)\n",
        "\n",
        "-> kết quả phân lớp của video 123 là lớp 2C\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61OzpyUqVarx"
      },
      "source": [
        "def video_report(model=None, testsets=None, device=\"cuda\"):\n",
        "  if testsets == None:\n",
        "    testsets = torchvision.datasets.ImageFolder(root=testdir, transform=transform_test_64)\n",
        "\n",
        "  video = namedtuple('video', ['id', \"label_true\", 'label_pred'])\n",
        "  path = [] # [158, 158, 158, 165, 165, 135, 135 ...]\n",
        "  for index, image in enumerate(testsets.imgs):\n",
        "    path.append(image[0].split(\"/\")[-1].split(\"_\")[0])\n",
        "\n",
        "  vid_list = [] # [158, 165, 135 ...]\n",
        "  for frame in path:\n",
        "    if (frame in vid_list) == False:\n",
        "      vid_list.append(frame)\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "  ytrue = []\n",
        "  ypred = []\n",
        "  model.to(device)\n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    for image, label in testsets:\n",
        "      image = image.unsqueeze(0).to(device)\n",
        "      output = model(image)\n",
        "      _, predicted = torch.max(output, dim=1)\n",
        "      ytrue.append(label)\n",
        "      ypred += list(predicted.cpu().numpy())\n",
        "\n",
        "  outputs_vid = []\n",
        "  ytrue_video = []\n",
        "  ypred_video = []\n",
        "  for vid_id in vid_list:\n",
        "    vid_true = []\n",
        "    vid_pred = []\n",
        "    for index, img in enumerate(path):\n",
        "      if img == vid_id:\n",
        "        vid_true.append(ytrue[index])\n",
        "        vid_pred.append(ypred[index])\n",
        "\n",
        "    rate_video_true = [0, 0, 0] # vector count for voting\n",
        "    rate_video_pred = [0, 0, 0]\n",
        "    for label in range(3):\n",
        "      rate_video_true[label] = list(vid_true).count(label)\n",
        "      rate_video_pred[label] = list(vid_pred).count(label)\n",
        "    \n",
        "    label_video_true = np.argmax(rate_video_true)\n",
        "    label_video_pred = np.argmax(rate_video_pred)\n",
        "\n",
        "    print(\"id:\", vid_id, \", true:\", label_video_true, \", pred:\",label_video_pred) # label pred\n",
        "    ytrue_video.append(label_video_true)\n",
        "    ypred_video.append(label_video_pred)\n",
        "    outputs_vid.append(video(id=vid_id, label_true=label_video_true, label_pred=label_video_pred))\n",
        "  print(classification_report(ytrue_video, ypred_video, target_names=get_classes()))\n",
        "  return outputs_vid\n"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yT_LgZ5PgYN1",
        "outputId": "079206f8-c1e1-48dd-f448-6b3553191e8a"
      },
      "source": [
        "testsets = torchvision.datasets.ImageFolder(root=testdir, transform=transform_test_normal)\n",
        "video_report(model=model, testsets=testsets,device =\"cuda\")\n",
        "# Bên dưới là kết quả thực hiện phân lớp bằng video của mô hình DENSENET121 với ảnh resize 224x224, không nhiễu, không tiền xử lý"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id: 158 , true: 0 , pred: 0\n",
            "id: 165 , true: 0 , pred: 0\n",
            "id: 168 , true: 0 , pred: 0\n",
            "id: 169 , true: 0 , pred: 0\n",
            "id: 171 , true: 0 , pred: 0\n",
            "id: 176 , true: 0 , pred: 0\n",
            "id: 177 , true: 0 , pred: 0\n",
            "id: 178 , true: 0 , pred: 0\n",
            "id: 181 , true: 0 , pred: 1\n",
            "id: 183 , true: 0 , pred: 0\n",
            "id: 191 , true: 0 , pred: 0\n",
            "id: 192 , true: 0 , pred: 0\n",
            "id: 157 , true: 1 , pred: 1\n",
            "id: 159 , true: 1 , pred: 1\n",
            "id: 161 , true: 1 , pred: 1\n",
            "id: 162 , true: 1 , pred: 1\n",
            "id: 166 , true: 1 , pred: 1\n",
            "id: 174 , true: 1 , pred: 0\n",
            "id: 175 , true: 1 , pred: 1\n",
            "id: 179 , true: 1 , pred: 1\n",
            "id: 185 , true: 1 , pred: 1\n",
            "id: 186 , true: 1 , pred: 1\n",
            "id: 189 , true: 1 , pred: 1\n",
            "id: 190 , true: 1 , pred: 1\n",
            "id: 194 , true: 1 , pred: 1\n",
            "id: 160 , true: 2 , pred: 1\n",
            "id: 163 , true: 2 , pred: 2\n",
            "id: 164 , true: 2 , pred: 2\n",
            "id: 167 , true: 2 , pred: 2\n",
            "id: 170 , true: 2 , pred: 2\n",
            "id: 172 , true: 2 , pred: 2\n",
            "id: 173 , true: 2 , pred: 2\n",
            "id: 180 , true: 2 , pred: 2\n",
            "id: 182 , true: 2 , pred: 2\n",
            "id: 184 , true: 2 , pred: 2\n",
            "id: 187 , true: 2 , pred: 2\n",
            "id: 188 , true: 2 , pred: 2\n",
            "id: 193 , true: 2 , pred: 2\n",
            "id: 195 , true: 2 , pred: 2\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          2C       0.92      0.92      0.92        12\n",
            "          3C       0.86      0.92      0.89        13\n",
            "          4C       1.00      0.93      0.96        14\n",
            "\n",
            "    accuracy                           0.92        39\n",
            "   macro avg       0.92      0.92      0.92        39\n",
            "weighted avg       0.93      0.92      0.92        39\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[video(id='158', label_true=0, label_pred=0),\n",
              " video(id='165', label_true=0, label_pred=0),\n",
              " video(id='168', label_true=0, label_pred=0),\n",
              " video(id='169', label_true=0, label_pred=0),\n",
              " video(id='171', label_true=0, label_pred=0),\n",
              " video(id='176', label_true=0, label_pred=0),\n",
              " video(id='177', label_true=0, label_pred=0),\n",
              " video(id='178', label_true=0, label_pred=0),\n",
              " video(id='181', label_true=0, label_pred=1),\n",
              " video(id='183', label_true=0, label_pred=0),\n",
              " video(id='191', label_true=0, label_pred=0),\n",
              " video(id='192', label_true=0, label_pred=0),\n",
              " video(id='157', label_true=1, label_pred=1),\n",
              " video(id='159', label_true=1, label_pred=1),\n",
              " video(id='161', label_true=1, label_pred=1),\n",
              " video(id='162', label_true=1, label_pred=1),\n",
              " video(id='166', label_true=1, label_pred=1),\n",
              " video(id='174', label_true=1, label_pred=0),\n",
              " video(id='175', label_true=1, label_pred=1),\n",
              " video(id='179', label_true=1, label_pred=1),\n",
              " video(id='185', label_true=1, label_pred=1),\n",
              " video(id='186', label_true=1, label_pred=1),\n",
              " video(id='189', label_true=1, label_pred=1),\n",
              " video(id='190', label_true=1, label_pred=1),\n",
              " video(id='194', label_true=1, label_pred=1),\n",
              " video(id='160', label_true=2, label_pred=1),\n",
              " video(id='163', label_true=2, label_pred=2),\n",
              " video(id='164', label_true=2, label_pred=2),\n",
              " video(id='167', label_true=2, label_pred=2),\n",
              " video(id='170', label_true=2, label_pred=2),\n",
              " video(id='172', label_true=2, label_pred=2),\n",
              " video(id='173', label_true=2, label_pred=2),\n",
              " video(id='180', label_true=2, label_pred=2),\n",
              " video(id='182', label_true=2, label_pred=2),\n",
              " video(id='184', label_true=2, label_pred=2),\n",
              " video(id='187', label_true=2, label_pred=2),\n",
              " video(id='188', label_true=2, label_pred=2),\n",
              " video(id='193', label_true=2, label_pred=2),\n",
              " video(id='195', label_true=2, label_pred=2)]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    }
  ]
}