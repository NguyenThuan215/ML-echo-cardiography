{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "echocardiography.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NguyenThuan215/ML-echo-cardiography/blob/main/echocardiography.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwSbWxosZDuO"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "from collections import namedtuple\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNtq4N34h4OD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9681fa04-36d9-404b-de41-08de85acca26"
      },
      "source": [
        "drive.mount(\"/content/drive\")\n",
        "!unzip -uq \"/content/drive/My Drive/DATA_CHAMBER_2021.zip\" -d \"./\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLgVpzcHrnw7"
      },
      "source": [
        "# traindir = \"/content/drive/MyDrive/Colab Notebooks/DATA_CHAMBER_2021/train\"\n",
        "# testdir = \"/content/drive/MyDrive/Colab Notebooks/DATA_CHAMBER_2021/test\"\n",
        "\n",
        "traindir = \"DATA_CHAMBER_2021/train\"\n",
        "testdir = \"DATA_CHAMBER_2021/test\"\n",
        "TrainTest = namedtuple('TrainTest', ['train', 'test'])\n",
        "\n",
        "def get_classes():\n",
        "  classes = ['2C', '3C', '4C']\n",
        "  return classes\n",
        "\n",
        "def prepare_data():\n",
        "  image_size = 64\n",
        "  transform_train = transforms.Compose([\n",
        "      transforms.Resize((image_size,image_size)),                                    \n",
        "      transforms.ToTensor(),\n",
        "      # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "  ])\n",
        "  transform_test = transforms.Compose([\n",
        "      transforms.Resize((image_size,image_size)),\n",
        "      transforms.ToTensor(),\n",
        "      # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "  ])\n",
        "  trainset = torchvision.datasets.ImageFolder(root=traindir, transform=transform_train)\n",
        "  testset = torchvision.datasets.ImageFolder(root=testdir, transform=transform_test)\n",
        "\n",
        "  print(\"Num Images in train set:\", len(trainset))\n",
        "  print(\"Num Images in test set:\", len(testset))\n",
        "  print(\"image size: \", trainset[0][0].shape)\n",
        "  print(\"class: \", trainset.class_to_idx)\n",
        "  return TrainTest(train=trainset, test=testset)\n",
        "\n",
        "def prepare_loader(datasets):\n",
        "  batch = 32\n",
        "  worker = 4\n",
        "  trainloader = DataLoader(dataset=datasets.train, batch_size=batch, shuffle=True, num_workers=worker)\n",
        "  testloader = DataLoader(dataset=datasets.test, batch_size=batch, shuffle=False, num_workers=worker)\n",
        "  print(\"Num batch in train set: \", len(trainloader))\n",
        "  return TrainTest(train=trainloader, test=testloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfc1-9U4OVSo"
      },
      "source": [
        "def train_epoch(epoch, model, loader, loss_func, optimizer, device):\n",
        "  model.train()\n",
        "  running_loss = 0.0\n",
        "  reporting_steps = 40\n",
        "  step = 0\n",
        "  for images, labels in loader:\n",
        "    step += 1\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    outputs = model(images)\n",
        "    loss = loss_func(outputs, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    if step % reporting_steps == reporting_steps - 1:\n",
        "      print(f\"Epoch {epoch} step {step} ave_loss {running_loss/reporting_steps:.4f}\")\n",
        "      running_loss = 0.0\n",
        "\n",
        "def test_epoch(epoch, model, loader, device):\n",
        "  ytrue = []\n",
        "  ypred = []\n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    for images, labels in loader:\n",
        "      images, labels = images.to(device), labels.to(device)\n",
        "      outputs = model(images)\n",
        "      _, predicted = torch.max(outputs, dim=1)\n",
        "      ytrue += list(labels.cpu().numpy())\n",
        "      ypred += list(predicted.cpu().numpy())\n",
        "\n",
        "  return ypred, ytrue"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWfJ2IN6iObn"
      },
      "source": [
        "def main(PATH='./model.pth', model_in=None):\n",
        "  classes = get_classes()\n",
        "  datasets = prepare_data()\n",
        "  loaders = prepare_loader(datasets)\n",
        "\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  print(\"\\ndevice:\", device)\n",
        "  print(\"model:\", model_in)\n",
        "\n",
        "  if model_in == 'vgg16':  \n",
        "    model = torchvision.models.vgg16()\n",
        "    model.classifier[6] = torch.nn.modules.linear.Linear(in_features=4096, out_features=3, bias=True)\n",
        "    model.to(device=device)\n",
        "  elif model_in == 'resnet50':\n",
        "    model = torchvision.models.resnet50()\n",
        "    model.fc = torch.nn.modules.linear.Linear(in_features=2048, out_features=3, bias=True) \n",
        "    model.to(device=device)\n",
        "  elif model_in == 'resnet18':\n",
        "    model = torchvision.models.resnet18()\n",
        "    model.fc = torch.nn.modules.linear.Linear(in_features=512, out_features=3, bias=True) \n",
        "    model.to(device=device)\n",
        "  else: \n",
        "    pass\n",
        "\n",
        "  loss_func = nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "  for epoch in range(20):\n",
        "    print(\"---------------------------------------------------------------\")\n",
        "    print(f\"\\nEpoch {epoch} report: \")\n",
        "    train_epoch(epoch, model, loaders.train, loss_func, optimizer, device)\n",
        "\n",
        "    # ypred_train, y_true_train = test_epoch(epoch, model, loaders.train, device)\n",
        "    ypred_test, ytrue_test = test_epoch(epoch, model, loaders.test, device)\n",
        "    print(\"Test report: \\n\", classification_report(ytrue_test, ypred_test, target_names=classes))\n",
        "\n",
        "    torch.save(model.state_dict(), PATH)\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNaRMKd7bEW5"
      },
      "source": [
        "model = main(PATH=\"./vgg16.pth\", model_in='vgg16')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvIUwXOnbRfy"
      },
      "source": [
        "model = main(PATH=\"./resnet18.pth\", model_in='resnet18')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11IjyYmDbRvH"
      },
      "source": [
        "model = main(PATH=\"./resnet50.pth\", model_in='resnet50')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuTypVjk3u44"
      },
      "source": [
        "### Kết quả"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQCAJH9LXDsu"
      },
      "source": [
        "# vgg16_64 = [0.25, 0.43, 0.66, 0.72, 0.80, 0.87, 0.90, 0.90, 0.90, 0.91]\n",
        "# vgg16_224 = [0.25, 0.61, 0.78, 0.83, 0.86, 0.87, 0.88, 0.92, 0.89, 0.90]\n",
        "\n",
        "# resnet18_64 = [0.56, 0.63, 0.75, 0.85, 0.89, 0.90, 0.90, 0.91, 0.90, 0.91]\n",
        "# resnet18_224 = [0.65, 0.53, 0.71, 0.81, 0.83, 0.89, 0.90, 0.91, 0.90, 0.92]\n",
        "\n",
        "# resnet50_64 = [0.65, 0.80, 0.79, 0.78, 0.80, 0.77, 0.83, 0.82, 0.82, 0.84]\n",
        "# resnet50_224 = [0.61, 0.77, 0.83, 0.83, 0.86, 0.81, 0.83, 0.89, 0.85, 0.87]\n",
        "\n",
        "# net = [vgg16_64, vgg16_224, resnet18_64, resnet18_224, resnet50_64, resnet50_224]\n",
        "# fig, ((ax1, ax2), (ax3, ax4), (ax5, ax6)) = plt.subplots(3,2, figsize=(15,18))\n",
        "\n",
        "# ax1.plot(vgg16_64, \"bo--\", label=\"64x64\")\n",
        "# ax1.set(title=\"VGG16 64x64\", xlabel=\"epoch\", ylabel=\"accuracy\",xlim=(-0.5,10), ylim=(0,1))\n",
        "# ax2.plot(vgg16_224, \"go--\", label=\"224x224\")\n",
        "# ax2.set(title=\"VGG16 224x224\", xlabel=\"epoch\", ylabel=\"accuracy\", xlim=(-0.5,10), ylim=(0,1))\n",
        "\n",
        "# ax3.plot(resnet18_64, \"bo--\", label=\"64x64\")\n",
        "# ax3.set(title=\"RESNET18 64x64\", xlabel=\"epoch\", ylabel=\"accuracy\",xlim=(-0.5,10), ylim=(0,1))\n",
        "# ax4.plot(resnet18_224, \"go--\", label=\"224x224\")\n",
        "# ax4.set(title=\"RESNET18 224x224\", xlabel=\"epoch\", ylabel=\"accuracy\", xlim=(-0.5,10), ylim=(0,1))\n",
        "\n",
        "# ax5.plot(resnet50_64, \"bo--\", label=\"64x64\")\n",
        "# ax5.set(title=\"RESNET50 64x64\", xlabel=\"epoch\", ylabel=\"accuracy\",xlim=(-0.5,10), ylim=(0,1))\n",
        "# ax6.plot(resnet50_224, \"go--\", label=\"224x224\")\n",
        "# ax6.set(title=\"RESNET50 224x224\", xlabel=\"epoch\", ylabel=\"accuracy\", xlim=(-0.5,10), ylim=(0,1))\n",
        "\n",
        "# fig.xlabel=\"x\"\n",
        "# fig.ylabel=\"y\"\n",
        "# plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}